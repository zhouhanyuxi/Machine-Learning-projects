{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Get Evaluation Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from check_result import evaluator\n",
    "\n",
    "full_set = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yili.lai/recognition/CUB_200_2011/images'\n",
    "test_set = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yili.lai/recognition/CUB_200_2011/test'\n",
    "\n",
    "evaluator = evaluator(full_set, test_set)\n",
    "\n",
    "test_list = evaluator.get_random_test_list(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_all = open('evaluation_average.csv', 'w', newline='')\n",
    "all_writer = csv.writer(file_all)\n",
    "all_writer.writerow([\"Name\",\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Multi-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import multisimilarity\n",
    "from torchvision import transforms as T\n",
    "import csv\n",
    "\n",
    "\n",
    "model = multisimilarity.BNInception(512)\n",
    "\n",
    "sz=224\n",
    "mean=[104, 117, 128]\n",
    "std=[1, 1, 1]\n",
    "\n",
    "def MUL(x):\n",
    "    return x.mul(255)\n",
    "\n",
    "def trans(im):\n",
    "    assert im.mode == 'RGB'\n",
    "    r, g, b = [im.getchannel(i) for i in range(3)]\n",
    "    # RGB mode also for BGR, 3x8-bit pixels, true color, see PIL doc\n",
    "    im = PIL.Image.merge('RGB', [b, g, r])\n",
    "    return im\n",
    "\n",
    "transform=T.Compose([\n",
    "        T.Lambda(trans),\n",
    "        T.Resize((sz,sz)),\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(MUL),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "r = retrieve(model=model, model_path=\"../model/multisimilarity.pth\", embedding_path=\"../embedding/MultiSimilarity.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('multisimilarity_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"multisimilarity\"]+total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import triplet\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean, std = 0.1307, 0.3081\n",
    "\n",
    "transform=transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                                                  transforms.Resize((28,28)),\n",
    "                                                                  transforms.ToTensor(),\n",
    "                                                                  transforms.Normalize((mean,), (std,))\n",
    "                                                                  ])\n",
    "\n",
    "r = retrieve(model=triplet.get_model(), model_path=\"../model/triplet_state.pth\", embedding_path=\"../embedding/triplet.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('triplet_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"triplet\"] + total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import contrastive\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean, std = 0.1307, 0.3081\n",
    "\n",
    "transform=transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                                                  transforms.Resize((28,28)),\n",
    "                                                                  transforms.ToTensor(),\n",
    "                                                                  transforms.Normalize((mean,), (std,))\n",
    "                                                                  ])\n",
    "\n",
    "r = retrieve(model=contrastive.get_model(), model_path=\"../model/contrastive_state.pth\", embedding_path=\"../embedding/contrastive.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('contrastive_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"contrastive\"] + total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## cosface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading LResNet model.\n",
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import cosface\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((112,96)),\n",
    "            transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]\n",
    "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 1.0] -> [-1.0,1.0]\n",
    "        ])\n",
    "\n",
    "\n",
    "r = retrieve(model=cosface.get_model(), model_path=\"../model/CosFace_half_data.pth\", embedding_path=\"../embedding/cosface1.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('cosface_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"cosface\"] + total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## softtriple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import softtriple\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "\n",
    "model = softtriple.BNInception(dim=512)\n",
    "\n",
    "def RGB2BGR(im):\n",
    "    assert im.mode == 'RGB'\n",
    "    r, g, b = im.split()\n",
    "    return PIL.Image.merge('RGB', (b, g, r))\n",
    "\n",
    "def MUL(x):\n",
    "    return x.mul(255)\n",
    "    \n",
    "normalize = transforms.Normalize(mean=[104., 117., 128.],\n",
    "                                 std=[1., 1., 1.])\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.Lambda(RGB2BGR),\n",
    "        transforms.Resize((224,224)),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(MUL),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "r = retrieve(model=model, model_path=\"../model/softtriple.pth\", embedding_path=\"../embedding/softtriple.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('softtriple_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"softtriple\"] + total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## arcface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import arcface\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "\n",
    "mean, std = 0.1307, 0.3081\n",
    "\n",
    "transform=transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                        transforms.Resize((128,128)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((mean,), (std,))\n",
    "                                        ])\n",
    "\n",
    "r = retrieve(model=arcface.get_model(), model_path=\"../model/arcfacemodel.pth\", embedding_path=\"../embedding/arcface.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('arcface_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"arcface\"] + total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## proxyNCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation!\n"
     ]
    }
   ],
   "source": [
    "from retrieve import retrieve\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import proxyNCA\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "\n",
    "class Identity(): # used for skipping transforms\n",
    "    def __call__(self, im):\n",
    "        return im\n",
    "\n",
    "class ScaleIntensities():\n",
    "    def __init__(self, in_range, out_range):\n",
    "        \"\"\" Scales intensities. For example [-1, 1] -> [0, 255].\"\"\"\n",
    "        self.in_range = in_range\n",
    "        self.out_range = out_range\n",
    "\n",
    "    def __oldcall__(self, tensor):\n",
    "        tensor.mul(255)\n",
    "        return tensor\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        tensor = (\n",
    "            tensor - self.in_range[0]\n",
    "        ) / (\n",
    "            self.in_range[1] - self.in_range[0]\n",
    "        ) * (\n",
    "            self.out_range[1] - self.out_range[0]\n",
    "        ) + self.out_range[0]\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class RGBToBGR():\n",
    "    def __call__(self, im):\n",
    "        assert im.mode == 'RGB'\n",
    "        r, g, b = [im.getchannel(i) for i in range(3)]\n",
    "        # RGB mode also for BGR, 3x8-bit pixels, true color, see PIL doc\n",
    "        im = PIL.Image.merge('RGB', [b, g, r])\n",
    "        return im\n",
    "\n",
    "def make_transform(sz_resize = 256, sz_crop = 227, mean = [104, 117, 128],\n",
    "        std = [1, 1, 1], rgb_to_bgr = True, is_train = True,\n",
    "        intensity_scale = [[0, 1],[0, 255]]):\n",
    "    return transforms.Compose([\n",
    "        RGBToBGR() if rgb_to_bgr else Identity(),\n",
    "        transforms.RandomResizedCrop(sz_crop) if is_train else Identity(),\n",
    "        transforms.Resize(sz_resize) if not is_train else Identity(),\n",
    "        transforms.CenterCrop(sz_crop) if not is_train else Identity(),\n",
    "        #transforms.HorizontalFlip() if is_train else Identity(),\n",
    "        transforms.ToTensor(),\n",
    "        ScaleIntensities(*intensity_scale) if intensity_scale is not None else Identity(),\n",
    "        transforms.Normalize(\n",
    "            mean=mean,\n",
    "            std=std,\n",
    "        )\n",
    "    ])\n",
    "\n",
    "transform = make_transform()\n",
    "\n",
    "r = retrieve(model=proxyNCA.get_model(), model_path=\"../model/ProxyNCA.pth\", embedding_path=\"../embedding/proxyNCA.csv\", image_path=\"image_path.csv\")\n",
    "# image = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yikai/code/Users/yikai.wang/ceshi/images/001.Black_footed_Albatross/Black_Footed_Albatross_0001_796111.jpg\"\n",
    "\n",
    "\n",
    "k = [1, 5, 10, 20, 30]\n",
    "total_precisions = [0, 0, 0, 0, 0]\n",
    "total_recalls = [0, 0, 0, 0, 0]\n",
    "\n",
    "file = open('proxyNCA_evaluation.csv', 'w', newline='')\n",
    "writer = csv.writer(file)\n",
    "writer.writerow([\"precision@1\", \"precision@5\", \"precision@10\",\"precision@20\", \"precision@30\", \"recall@1\", \"recall@5\", \"recall@10\",\"recall@20\", \"recall@30\"])\n",
    "\n",
    "for image in test_list:\n",
    "    image = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ton/code/Users/yikai.wang/ceshi/images/' + image\n",
    "    result = r.get_k_image_path(image, transform, k=30)\n",
    "    precisions = evaluator.get_precision(image, result, k)\n",
    "    recalls = evaluator.get_recall(image, result, k)\n",
    "    writer.writerow(precisions+recalls)\n",
    "    \n",
    "    for i in range(5):\n",
    "        total_precisions[i] += precisions[i]\n",
    "        total_recalls[i] += recalls[i]\n",
    "\n",
    "file.close()\n",
    "\n",
    "for i in range(5):\n",
    "        total_precisions[i] += precisions[i]/200\n",
    "        total_recalls[i] += recalls[i]/200\n",
    "\n",
    "all_writer.writerow([\"proxyNCA\"] + total_precisions+total_recalls)\n",
    "print(\"Finished Evaluation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "file_all.close()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
